{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Model\n",
    "\n",
    "Data has been already cleaned in SQL.\n",
    "\n",
    "A database with a timestamp every 5 min was created with the station and weather data.\n",
    "The day-time savings time change was adjusted.\n",
    "A column for the day was added.\n",
    "The status for the night was corrected to closed.\n",
    "The CSV clean_db.csv was created from that. This database will be used as test and validation set for this prediction model.\n",
    "Column with just time.\n",
    "\n",
    "For the prediction model there will be a random forest regression done for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "# Import package pandas for data analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Import package numpy for numeric computing\n",
    "import numpy as np\n",
    "\n",
    "# Import package matplotlib for visualisation/plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports for random forest regression\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# For showing plots directly in the notebook run the command below\n",
    "%matplotlib inline\n",
    "\n",
    "# Connect DB\n",
    "import sys\n",
    "sys.path.append('../web/')\n",
    "from dbConnection import connect_db, get_clean_db\n",
    "\n",
    "\n",
    "# Pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from a csv file, into a data frame\n",
    "df = pd.read_csv(\"/Users/florian/Documents/GitHub/clean_db.csv\", keep_default_na=True, dtype={16: str}, delimiter=',', skipinitialspace=True, encoding='Windows-1252') #sep=',\\s+',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql_query = get_clean_db()\n",
    "#df = pd.DataFrame(sql_query, columns = ['timestamp', 'station_id', 'available_bikes', 'available_bike_stands', 'status', 'temperature', 'pressure', 'humidity', 'clouds', 'wind_speed_beaufort', 'wind_direction', 'precipitation_value', 'precipitation_min', 'precipitation_max', 'precipitation_probability', 'wind_speed_mps', 'weather_type', 'icon_number', 'temperature_feels_like', 'day_flag', 'time', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows: \" + str(df.shape[0]))\n",
    "print(\"Columns: \" + str(df.shape[1]))\n",
    "print(df.columns)\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type changes & drops\n",
    "df.drop(['weather_type', 'icon_number'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"time\"] = pd.to_datetime(df[\"time\"], format=\"%H:%M:%S\")\n",
    "df[\"time\"] = df[\"time\"].dt.strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_category(column):\n",
    "    list_unique = []\n",
    "    for i in sorted(df[column].unique()):\n",
    "        list_unique.append(i)\n",
    "\n",
    "    list_range = [i for i in range(len(list_unique))]\n",
    "    df[column] = df[column].astype('category')\n",
    "    df[column].cat.add_categories(list_range, inplace=True)\n",
    "\n",
    "    df[column] = df[column].replace(list_unique, list_range)\n",
    "    df[column] = df[column].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_category(\"status\")\n",
    "to_category(\"time\")\n",
    "to_category(\"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"status\"].ravel())\n",
    "print(df[\"time\"].ravel())\n",
    "print(df[\"day\"].ravel())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of availability\n",
    "\n",
    "df['availabilty_ratio'] = df['available_bikes'] / (df['available_bikes'] + df['available_bike_stands'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['availabilty_ratio'].isnull()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Seems to be an error or a time where station is closed if bike and stands is 0. Those rows will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['availabilty_ratio'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_stands'] = df['available_bikes'] + df['available_bike_stands']\n",
    "stations_unique = sorted(df[\"station_id\"].unique())\n",
    "for station in stations_unique:\n",
    "    df_station = df.loc[df[\"station_id\"] == station]\n",
    "    df_clean_station = df_station.loc[df_station[\"max_stands\"] == df_station[\"max_stands\"].median()]\n",
    "    print(station, \"min:\", df_station[\"max_stands\"].min(), \"mean:\", df_station[\"max_stands\"].median(),\"max:\", df_station[\"max_stands\"].max(),\"-\", df_station.shape[0] - df_clean_station.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[(df[\"max_stands\"].median()-3 < df[\"max_stands\"]) & (df[\"max_stands\"] < df[\"max_stands\"].median()+3)].shape[0])\n",
    "print(df.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Seems like many rows don't add up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in stations_unique:\n",
    "    df.loc[df[\"station_id\"] == station, 'max_stands'] = round(df.loc[df[\"station_id\"] == station, 'max_stands'].median())\n",
    "\n",
    "for station in stations_unique:\n",
    "    df_station = df.loc[df[\"station_id\"] == station]\n",
    "    df_clean_station = df_station.loc[df_station[\"max_stands\"] == df_station[\"max_stands\"].median()]\n",
    "    print(station, \"min:\", df_station[\"max_stands\"].min(), \"mean:\", df_station[\"max_stands\"].median(),\"max:\", df_station[\"max_stands\"].max(),\"-\", df_station.shape[0] - df_clean_station.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo: Ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['availabilty_ratio'] = df['available_bikes'] / df['max_stands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df):\n",
    "    # Correlation matrix using code found on https://stanford.edu/~mwaskom/software/seaborn/examples/many_pairwise_correlations.html\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Calculate correlation of all pairs of continuous features\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom colormap - blue and red\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, annot=True, mask=mask, cmap=cmap, vmax=1, vmin=-1,\n",
    "                square=True, xticklabels=True, yticklabels=True,\n",
    "                linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "    plt.yticks(rotation = 0)\n",
    "    plt.xticks(rotation = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = df.loc[df[\"station_id\"] == 1]\n",
    "#correlation(df_station)\n",
    "corr = df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_tables = []\n",
    "for station in stations_unique:\n",
    "    df_station = df.loc[df[\"station_id\"] == station]\n",
    "    correlation_tables.append(df_station.corr())\n",
    "\n",
    "# Concatenate the correlation tables into a single dataframe\n",
    "merged_corr_table = pd.concat(correlation_tables)\n",
    "correlation(merged_corr_table)\n",
    "\n",
    "# average correlation - in relation to each station"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "- precipitation_min / _max / _value seem to represent a similar value with similar correlation. Will be reduced to just the _value.\n",
    "- wind direction and speed seem to have little influence and will be dropped as well\n",
    "- all rows with status \"CLOSED\" will be dropped and then the column will be dropped - not relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"status\"] == 1]\n",
    "df.drop(['precipitation_min', 'precipitation_max', 'wind_speed_mps', 'wind_direction', 'wind_speed_beaufort', 'status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop temperature_feels_like and day_flag as we don't have them for future values:\n",
    "df = df.drop(['temperature_feels_like', 'day_flag'],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Flag columns for chance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bikes_flag'] = df['available_bikes'].apply(lambda x: 0 if x == 0 else 1)\n",
    "df['stands_flag'] = df['available_bike_stands'].apply(lambda x: 0 if x == 0 else 1)\n",
    "df.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historical Data db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_clean_df = df.drop(['temperature', 'pressure', 'humidity', 'clouds', 'precipitation_value', 'precipitation_probability'],axis=1)\n",
    "prediction_clean_df.to_csv(\"prediction_clean_df.csv\", index=False)\n",
    "prediction_clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write clean_db in CSV\n",
    "df.drop(['timestamp'], axis=1, inplace=True)\n",
    "df.to_csv(\"cleaned_clean_db.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first test an overall model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['station_id', 'available_bikes', 'available_bike_stands', 'availabilty_ratio', 'max_stands', 'bikes_flag', 'stands_flag'],axis=1)\n",
    "y = df['availabilty_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators = 100, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the prediction\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "print(\"Mean absolute error:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"Root Mean Square Error:\", metrics.mean_squared_error(y_test, y_pred)**0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Not really precise. 0.3 root mean square error for a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.ylabel('Predicted DT')\n",
    "plt.xlabel('Actual DT')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Prediction seems to be really inaccurate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Training\n",
    "Source for following parameter tuning: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Random Search\n",
    "To determine if random search yielded a better model, we compare the base model with the best random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    RMSE = metrics.mean_squared_error(test_labels, regr.predict(test_features))**0.5\n",
    "    errors = abs(predictions - test_labels)\n",
    "    #mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - (100*RMSE)\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('RMSE: {:0.4f}.'.format(RMSE))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "base_model = regr\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> not worth the perfomance needed to improve the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First test with the first stations and a plot\n",
    "\n",
    "prediction_models = {}\n",
    "for station in stations_unique[:5]:\n",
    "        df_station = df.loc[df[\"station_id\"] == station]\n",
    "        X = df_station.drop(['station_id', 'available_bikes', 'available_bike_stands', 'availabilty_ratio', 'max_stands', 'bikes_flag', 'stands_flag'],axis=1)\n",
    "        y = df_station['availabilty_ratio']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "        \n",
    "        regr = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "        regr.fit(X_train, y_train)\n",
    "\n",
    "        prediction_models[station] = regr\n",
    "\n",
    "        y_pred = regr.predict(X_test)\n",
    "\n",
    "        print(\"Mean absolute error:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "        print(\"Root Mean Square Error:\", metrics.mean_squared_error(y_test, y_pred)**0.5)\n",
    "\n",
    "        plt.scatter(y_test, y_pred)\n",
    "        plt.ylabel('Predicted DT')\n",
    "        plt.xlabel('Actual DT')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific models seem to be much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of training models:\n",
    "def training(base_model, X_train, X_test, y_train, y_test):\n",
    "        # Number of trees in random forest\n",
    "        n_estimators = [int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)]\n",
    "        # Number of features to consider at every split\n",
    "        max_features = ['auto', 'sqrt']\n",
    "        # Maximum number of levels in tree\n",
    "        max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "        max_depth.append(None)\n",
    "        # Minimum number of samples required to split a node\n",
    "        min_samples_split = [2, 5, 10]\n",
    "        # Minimum number of samples required at each leaf node\n",
    "        min_samples_leaf = [1, 2, 4]\n",
    "        # Method of selecting samples for training each tree\n",
    "        bootstrap = [True, False]\n",
    "        # Create the random grid\n",
    "        random_grid = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap}\n",
    "\n",
    "        # Use the random grid to search for best hyperparameters\n",
    "        # First create the base model to tune\n",
    "        rf = RandomForestRegressor(random_state = 42)\n",
    "        # Random search of parameters, using 3 fold cross validation, \n",
    "        # search across 100 different combinations, and use all available cores\n",
    "        rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "        # Fit the random search model\n",
    "        rf_random.fit(X_train, y_train)\n",
    "\n",
    "        base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "        best_random = rf_random.best_estimator_\n",
    "        random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "        print('----------------------------------------------------------')\n",
    "        print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))\n",
    "        print('----------------------------------------------------------')\n",
    "\n",
    "\n",
    "prediction_models = {}\n",
    "for station in stations_unique[:5]:\n",
    "        df_station = df.loc[df[\"station_id\"] == station]\n",
    "        X = df_station.drop(['station_id', 'available_bikes', 'available_bike_stands', 'availabilty_ratio', 'max_stands'],axis=1)\n",
    "        y = df_station['availabilty_ratio']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "        \n",
    "        regr = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "        regr.fit(X_train, y_train)\n",
    "\n",
    "        prediction_models[station] = regr\n",
    "\n",
    "        y_pred = regr.predict(X_test)\n",
    "\n",
    "        print(\"Mean absolute error:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "        print(\"Root Mean Square Error:\", metrics.mean_squared_error(y_test, y_pred)**0.5)\n",
    "\n",
    "        training(regr, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: For this sample the training did not improve the accuracy, so we won't train each model to reduce on performance needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_models = {}\n",
    "for station in stations_unique:\n",
    "        df_station = df.loc[df[\"station_id\"] == station]\n",
    "        max_stands = df.loc[df[\"station_id\"] == station][\"max_stands\"].max()\n",
    "        X = df_station.drop(['station_id', 'available_bikes', 'available_bike_stands', 'availabilty_ratio', 'max_stands', 'bikes_flag', 'stands_flag'],axis=1)\n",
    "        y = df_station['availabilty_ratio']\n",
    "        y_bike_chance = df_station['bikes_flag']\n",
    "        y_stands_chance = df_station['stands_flag']\n",
    "\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "        \n",
    "        regr = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "        regr.fit(X, y)\n",
    "\n",
    "        regr_bike_chance = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "        regr_bike_chance.fit(X, y_bike_chance)\n",
    "\n",
    "        regr_stands_chance = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "        regr_stands_chance.fit(X, y_stands_chance)\n",
    "\n",
    "        prediction_models[station] = [regr.predict, max_stands, regr_bike_chance.predict, regr_stands_chance.predict]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction\n",
    "# ['temperature', 'pressure', 'humidity', 'clouds', 'precipitation_value', 'precipitation_probability', 'time', 'day']\n",
    "test_values = np.array([[6, 1026.5, 60.4, 79.9, 0, 0, 150, 4]])\n",
    "pred = prediction_models[1][0](test_values)\n",
    "pred_chance = prediction_models[1][2](test_values)\n",
    "pred_stand_chance = prediction_models[1][3](test_values)\n",
    "print(pred)\n",
    "print(float(pred_chance))\n",
    "print(pred_stand_chance)\n",
    "print(pred * prediction_models[1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_bike_prediction(station_id, date, temperature, pressure, humidity, clouds, precipitation_value, precipitation_probability):\n",
    "   \"\"\" date as string: '2023-05-02 23:59:59' \"\"\"\n",
    "   # time conversion:\n",
    "   # hours * 12 + minutes//5 * 1\n",
    "   time = int(date[11:13]) * 12 + int(date[14:16])//5\n",
    "   # day conversion:\n",
    "   d = pd.Timestamp(date[:10])\n",
    "   day = d.dayofweek\n",
    "\n",
    "   input_value = np.array([[temperature, pressure, humidity, clouds, precipitation_value, precipitation_probability, time, day]])\n",
    "   pred = int(prediction_models[station_id][0](input_value))\n",
    "   pred_bikes = pred * prediction_models[station_id][1]\n",
    "   pred_stations = prediction_models[station_id][1]-pred_bikes\n",
    "   return pred_bikes, pred_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian/opt/anaconda3/envs/comp30830/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bike, stands = get_available_bike_prediction(1, '2023-05-02 23:59:59', 6, 1026.5, 60.4, 79.9, 0, 0)\n",
    "print(bike, stands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export function:\n",
    "with open('predictionModels.pkl', 'wb') as file:\n",
    "    pickle.dump(prediction_models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. Bitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. Klicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. Weitere Details finden Sie in Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# Code for pickle file per station:\n",
    "prediction_models = {}\n",
    "for station in stations_unique:\n",
    "        df_station = df.loc[df[\"station_id\"] == station]\n",
    "        max_stands = df.loc[df[\"station_id\"] == station][\"max_stands\"].max()\n",
    "        X = df_station.drop(['station_id', 'available_bikes', 'available_bike_stands', 'availabilty_ratio', 'max_stands', 'bikes_flag', 'stands_flag'],axis=1)\n",
    "        y = df_station['availabilty_ratio']\n",
    "        y_bike_chance = df_station['bikes_flag']\n",
    "        y_stands_chance = df_station['stands_flag']\n",
    "        \n",
    "        regr = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "        regr.fit(X, y)\n",
    "\n",
    "        regr_bike_chance = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "        regr_bike_chance.fit(X, y_bike_chance)\n",
    "\n",
    "        regr_stands_chance = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "        regr_stands_chance.fit(X, y_stands_chance)\n",
    "\n",
    "        prediction_models[station] = [regr.predict, max_stands, regr_bike_chance.predict, regr_stands_chance.predict]\n",
    "\n",
    "        with open(f'station_models/predictionModels_{station}.pkl', 'wb') as file:\n",
    "            pickle.dump([regr.predict, max_stands, regr_bike_chance.predict, regr_stands_chance.predict], file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp30830",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
